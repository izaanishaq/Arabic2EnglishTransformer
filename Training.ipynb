{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:18:51.911712Z",
     "iopub.status.busy": "2025-02-27T10:18:51.911480Z",
     "iopub.status.idle": "2025-02-27T10:18:55.754042Z",
     "shell.execute_reply": "2025-02-27T10:18:55.753141Z",
     "shell.execute_reply.started": "2025-02-27T10:18:51.911678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ar import Arabic\n",
    "from datasets import load_dataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:18:55.756019Z",
     "iopub.status.busy": "2025-02-27T10:18:55.755443Z",
     "iopub.status.idle": "2025-02-27T10:19:02.249952Z",
     "shell.execute_reply": "2025-02-27T10:19:02.248940Z",
     "shell.execute_reply.started": "2025-02-27T10:18:55.755984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Arabic (src) vocabulary: 8520\n",
      "Size of English (tgt) vocabulary: 4902\n"
     ]
    }
   ],
   "source": [
    "# Load the Helsinki-NLP Arabic-English dataset\n",
    "dataset = load_dataset('Helsinki-NLP/tatoeba_mt', 'ara-eng')\n",
    "\n",
    "# Use \"validation\" as training and \"test\" as validation (since there is no training split)\n",
    "df_train = pd.DataFrame(dataset[\"validation\"])\n",
    "df_valid = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# Rename columns to match our expected fields: \"ar\" for Arabic and \"eng\" for English\n",
    "df_train = df_train.rename(columns={\"sourceString\": \"ar\", \"targetString\": \"eng\"})\n",
    "df_valid = df_valid.rename(columns={\"sourceString\": \"ar\", \"targetString\": \"eng\"})\n",
    "\n",
    "# Initialize spacy tokenizers\n",
    "enNLP = English()\n",
    "arNLP = Arabic()\n",
    "enTokenizer = Tokenizer(enNLP.vocab)\n",
    "arTokenizer = Tokenizer(arNLP.vocab)\n",
    "\n",
    "def myTokenizerEN(x):\n",
    "    # Clean and tokenize English text.\n",
    "    text = re.sub(r\"[\\.\\'\\`\\\"\\r\\n+]\", \" \", x.lower())\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return [word.text for word in enTokenizer(text)]\n",
    "\n",
    "def myTokenizerAR(x):\n",
    "    # Clean and tokenize Arabic text.\n",
    "    text = re.sub(r\"[\\.\\'\\`\\\"\\r\\n+]\", \" \", x.lower())\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return [word.text for word in arTokenizer(text)]\n",
    "\n",
    "# Special tokens\n",
    "SRC_SPECIALS = [\"<pad>\", \"<unk>\", \"ببدأ\", \"نهها\"]     # For Arabic, init and eos tokens are given.\n",
    "TGT_SPECIALS = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
    "\n",
    "def build_vocab(texts, tokenizer, min_freq=2, specials=None):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = tokenizer(text)\n",
    "        counter.update(tokens)\n",
    "    # Start with the special tokens\n",
    "    specials = specials if specials is not None else []\n",
    "    vocab_tokens = specials.copy()\n",
    "    # Add tokens with frequency >= min_freq\n",
    "    for tok, freq in counter.items():\n",
    "        if freq >= min_freq and tok not in vocab_tokens:\n",
    "            vocab_tokens.append(tok)\n",
    "    # Create mapping dictionaries\n",
    "    stoi = {tok: i for i, tok in enumerate(vocab_tokens)}\n",
    "    itos = {i: tok for tok, i in stoi.items()}\n",
    "    return type(\"Vocab\", (), {\"stoi\": stoi, \"itos\": itos, \"size\": len(stoi)})\n",
    "\n",
    "# Build vocabulary on the training set texts\n",
    "src_vocab = build_vocab(df_train[\"ar\"], myTokenizerAR, min_freq=2, specials=SRC_SPECIALS)\n",
    "tgt_vocab = build_vocab(df_train[\"eng\"], myTokenizerEN, min_freq=2, specials=TGT_SPECIALS)\n",
    "\n",
    "print(\"Size of Arabic (src) vocabulary:\", src_vocab.size)\n",
    "print(\"Size of English (tgt) vocabulary:\", tgt_vocab.size)\n",
    "\n",
    "#%% [code]\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df, src_tokenizer, tgt_tokenizer,\n",
    "                 src_vocab, tgt_vocab,\n",
    "                 src_init_token=\"ببدأ\", src_eos_token=\"نهها\",\n",
    "                 tgt_init_token=\"<sos>\", tgt_eos_token=\"<eos>\"):\n",
    "        self.df = df\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.src_init_token = src_init_token\n",
    "        self.src_eos_token = src_eos_token\n",
    "        self.tgt_init_token = tgt_init_token\n",
    "        self.tgt_eos_token = tgt_eos_token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        src_text, tgt_text = row[\"ar\"], row[\"eng\"]\n",
    "        src_tokens = [self.src_init_token] + self.src_tokenizer(src_text) + [self.src_eos_token]\n",
    "        tgt_tokens = [self.tgt_init_token] + self.tgt_tokenizer(tgt_text) + [self.tgt_eos_token]\n",
    "        src_indices = [self.src_vocab.stoi.get(tok, self.src_vocab.stoi[\"<unk>\"]) for tok in src_tokens]\n",
    "        tgt_indices = [self.tgt_vocab.stoi.get(tok, self.tgt_vocab.stoi[\"<unk>\"]) for tok in tgt_tokens]\n",
    "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of (src_tensor, tgt_tensor)\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=src_vocab.stoi[\"<pad>\"])\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=tgt_vocab.stoi[\"<pad>\"])\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = TranslationDataset(df_train, myTokenizerAR, myTokenizerEN, src_vocab, tgt_vocab)\n",
    "valid_dataset = TranslationDataset(df_valid, myTokenizerAR, myTokenizerEN, src_vocab, tgt_vocab)\n",
    "\n",
    "BATCH_SIZE = 150\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "#%% [code]\n",
    "class TranslateTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        max_len,\n",
    "    ):\n",
    "        super(TranslateTransformer, self).__init__()\n",
    "        self.srcEmbeddings = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.trgEmbeddings = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.srcPositionalEmbeddings = nn.Embedding(max_len, embedding_size)\n",
    "        self.trgPositionalEmbeddings = nn.Embedding(max_len, embedding_size)\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "        return src_mask.to(device)\n",
    "    \n",
    "    def forward(self, x, trg):\n",
    "        src_seq_length = x.shape[0]\n",
    "        batch_size = x.shape[1]\n",
    "        trg_seq_length = trg.shape[0]\n",
    "        \n",
    "        src_positions = torch.arange(0, src_seq_length).unsqueeze(1).expand(src_seq_length, batch_size).to(device)\n",
    "        trg_positions = torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length, batch_size).to(device)\n",
    "        \n",
    "        src_embedded = self.srcEmbeddings(x.long()) + self.srcPositionalEmbeddings(src_positions.long())\n",
    "        trg_embedded = self.trgEmbeddings(trg.long()) + self.trgPositionalEmbeddings(trg_positions.long())\n",
    "        \n",
    "        src_embedded = self.dropout(src_embedded)\n",
    "        trg_embedded = self.dropout(trg_embedded)\n",
    "        \n",
    "        src_padding_mask = self.make_src_mask(x)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(device)\n",
    "        \n",
    "        out = self.transformer(\n",
    "            src_embedded,\n",
    "            trg_embedded,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:19:02.251975Z",
     "iopub.status.busy": "2025-02-27T10:19:02.251707Z",
     "iopub.status.idle": "2025-02-27T10:19:02.609447Z",
     "shell.execute_reply": "2025-02-27T10:19:02.608478Z",
     "shell.execute_reply.started": "2025-02-27T10:19:02.251952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "max_len = 256\n",
    "embedding_size = 256\n",
    "src_pad_idx = src_vocab.stoi[\"<pad>\"]\n",
    "\n",
    "model = TranslateTransformer(\n",
    "    embedding_size,\n",
    "    src_vocab.size,\n",
    "    tgt_vocab.size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    max_len\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:19:02.610720Z",
     "iopub.status.busy": "2025-02-27T10:19:02.610461Z",
     "iopub.status.idle": "2025-02-27T10:32:17.720471Z",
     "shell.execute_reply": "2025-02-27T10:32:17.719532Z",
     "shell.execute_reply.started": "2025-02-27T10:19:02.610699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "EPOCHS = 30  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003) \n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.stoi[\"<pad>\"])\n",
    "\n",
    "loss_track = []\n",
    "loss_validation_track = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    stepLoss = []\n",
    "    \n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Training\", leave=True, dynamic_ncols=True, mininterval=1.0)\n",
    "    for i, (src_batch, tgt_batch) in enumerate(train_loop):\n",
    "        input_sentence = src_batch.to(device)\n",
    "        trg = tgt_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_sentence, trg[:-1])\n",
    "        output = output.reshape(-1, tgt_vocab.size)\n",
    "        trg_target = trg[1:].reshape(-1)\n",
    "        loss = criterion(output, trg_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        stepLoss.append(loss.item())\n",
    "\n",
    "        if i % 10 == 0:  \n",
    "            train_loop.set_postfix(loss=f\"{np.mean(stepLoss[-10:]):.4f}\")\n",
    "        \n",
    "    epoch_train_loss = np.mean(stepLoss)\n",
    "    loss_track.append(epoch_train_loss)\n",
    "    print(f\"Epoch {epoch+1} Train Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    stepValidLoss = []\n",
    "    with torch.no_grad():\n",
    "        for src_batch, tgt_batch in valid_loader: \n",
    "            input_sentence = src_batch.to(device)\n",
    "            trg = tgt_batch.to(device)\n",
    "            output = model(input_sentence, trg[:-1])\n",
    "            output = output.reshape(-1, tgt_vocab.size)\n",
    "            trg_target = trg[1:].reshape(-1)\n",
    "            loss = criterion(output, trg_target)\n",
    "            stepValidLoss.append(loss.item())\n",
    "\n",
    "    epoch_valid_loss = np.mean(stepValidLoss)\n",
    "    loss_validation_track.append(epoch_valid_loss)\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {epoch_valid_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:46:39.234429Z",
     "iopub.status.busy": "2025-02-27T10:46:39.234125Z",
     "iopub.status.idle": "2025-02-27T10:46:39.904968Z",
     "shell.execute_reply": "2025-02-27T10:46:39.903877Z",
     "shell.execute_reply.started": "2025-02-27T10:46:39.234405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully at model_checkpoint.pt!\n"
     ]
    }
   ],
   "source": [
    "checkpoint = {\n",
    "    \"epoch\": EPOCHS,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"loss_track\": loss_track,\n",
    "    \"loss_validation_track\": loss_validation_track,\n",
    "    \"src_vocab_tokens\": [src_vocab.itos[i] for i in range(src_vocab.size)],\n",
    "    \"tgt_vocab_tokens\": [tgt_vocab.itos[i] for i in range(tgt_vocab.size)],\n",
    "    \"config\": {\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"num_encoder_layers\": num_encoder_layers,\n",
    "        \"num_decoder_layers\": num_decoder_layers,\n",
    "        \"max_len\": max_len,\n",
    "        \"src_pad_idx\": src_vocab.stoi[\"<pad>\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path = \"model_checkpoint.pt\"\n",
    "torch.save(checkpoint, save_path)\n",
    "print(f\"Checkpoint saved successfully at {save_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:19:02.610720Z",
     "iopub.status.busy": "2025-02-27T10:19:02.610461Z",
     "iopub.status.idle": "2025-02-27T10:32:17.720471Z",
     "shell.execute_reply": "2025-02-27T10:32:17.719532Z",
     "shell.execute_reply.started": "2025-02-27T10:19:02.610699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.70it/s, loss=5.3249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 5.8562\n",
      "Epoch 1 Validation Loss: 5.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.77it/s, loss=4.8504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train Loss: 5.0339\n",
      "Epoch 2 Validation Loss: 4.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.87it/s, loss=4.4770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train Loss: 4.5809\n",
      "Epoch 3 Validation Loss: 4.3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.83it/s, loss=4.2122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train Loss: 4.2997\n",
      "Epoch 4 Validation Loss: 4.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.76it/s, loss=3.9830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train Loss: 4.0796\n",
      "Epoch 5 Validation Loss: 3.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.83it/s, loss=3.8574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train Loss: 3.8901\n",
      "Epoch 6 Validation Loss: 3.7783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.87it/s, loss=3.7403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train Loss: 3.7164\n",
      "Epoch 7 Validation Loss: 3.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.73it/s, loss=3.5273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train Loss: 3.5525\n",
      "Epoch 8 Validation Loss: 3.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.76it/s, loss=3.3905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train Loss: 3.3952\n",
      "Epoch 9 Validation Loss: 3.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.84it/s, loss=3.3209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train Loss: 3.2490\n",
      "Epoch 10 Validation Loss: 3.4336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.83it/s, loss=3.0832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train Loss: 3.1056\n",
      "Epoch 11 Validation Loss: 3.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.84it/s, loss=3.0463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train Loss: 2.9606\n",
      "Epoch 12 Validation Loss: 3.3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.79it/s, loss=2.7853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train Loss: 2.8190\n",
      "Epoch 13 Validation Loss: 3.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.91it/s, loss=2.6664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train Loss: 2.6815\n",
      "Epoch 14 Validation Loss: 3.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.88it/s, loss=2.5231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train Loss: 2.5430\n",
      "Epoch 15 Validation Loss: 3.2204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.87it/s, loss=2.3901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train Loss: 2.4057\n",
      "Epoch 16 Validation Loss: 3.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.79it/s, loss=2.3449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train Loss: 2.2729\n",
      "Epoch 17 Validation Loss: 3.1707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 Training: 100%|██████████| 131/131 [00:21<00:00,  5.95it/s, loss=2.1678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train Loss: 2.1385\n",
      "Epoch 18 Validation Loss: 3.1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.83it/s, loss=2.0596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train Loss: 2.0074\n",
      "Epoch 19 Validation Loss: 3.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.83it/s, loss=1.9194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train Loss: 1.8754\n",
      "Epoch 20 Validation Loss: 3.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.77it/s, loss=1.7860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train Loss: 1.7476\n",
      "Epoch 21 Validation Loss: 3.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.80it/s, loss=1.6566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train Loss: 1.6317\n",
      "Epoch 22 Validation Loss: 3.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.71it/s, loss=1.5498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train Loss: 1.5108\n",
      "Epoch 23 Validation Loss: 3.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.86it/s, loss=1.4060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train Loss: 1.3907\n",
      "Epoch 24 Validation Loss: 3.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.74it/s, loss=1.3772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train Loss: 1.2932\n",
      "Epoch 25 Validation Loss: 3.1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.78it/s, loss=1.2470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train Loss: 1.1872\n",
      "Epoch 26 Validation Loss: 3.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.76it/s, loss=1.1523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train Loss: 1.0870\n",
      "Epoch 27 Validation Loss: 3.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.73it/s, loss=1.0697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train Loss: 0.9948\n",
      "Epoch 28 Validation Loss: 3.2686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.73it/s, loss=0.9497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train Loss: 0.9197\n",
      "Epoch 29 Validation Loss: 3.3104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 Training: 100%|██████████| 131/131 [00:22<00:00,  5.86it/s, loss=0.8942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train Loss: 0.8442\n",
      "Epoch 30 Validation Loss: 3.3411\n",
      "Checkpoint saved successfully at model_checkpoint.pt!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:17:47.966650Z",
     "iopub.status.busy": "2025-02-27T10:17:47.966284Z",
     "iopub.status.idle": "2025-02-27T10:17:48.519274Z",
     "shell.execute_reply": "2025-02-27T10:17:48.518477Z",
     "shell.execute_reply.started": "2025-02-27T10:17:47.966622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-5f768243046a>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_checkpoint.pt\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function to rebuild the Vocab object from an ordered token list.\n",
    "def load_vocab_from_tokens(token_list):\n",
    "    Vocab = type(\"Vocab\", (), {})  # recreating the simple vocab type\n",
    "    vocab = Vocab()\n",
    "    vocab.stoi = {token: i for i, token in enumerate(token_list)}\n",
    "    vocab.itos = {i: token for i, token in enumerate(token_list)}\n",
    "    vocab.size = len(token_list)\n",
    "    return vocab\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"model_checkpoint.pt\", map_location=device)\n",
    "config = checkpoint[\"config\"]\n",
    "\n",
    "# Reassemble vocabulary objects using the stored token lists.\n",
    "src_vocab = load_vocab_from_tokens(checkpoint[\"src_vocab_tokens\"])\n",
    "tgt_vocab = load_vocab_from_tokens(checkpoint[\"tgt_vocab_tokens\"])\n",
    "\n",
    "# Re-create the model architecture using the configuration from the checkpoint.\n",
    "model = TranslateTransformer(\n",
    "    config[\"embedding_size\"],\n",
    "    src_vocab.size,\n",
    "    tgt_vocab.size,\n",
    "    config[\"src_pad_idx\"],\n",
    "    config[\"num_heads\"],\n",
    "    config[\"num_encoder_layers\"],\n",
    "    config[\"num_decoder_layers\"],\n",
    "    config[\"max_len\"]\n",
    ").to(device)\n",
    "\n",
    "# Load model and optimizer states.\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = optim.Adam(model.parameters())  # Recreate optimizer if needed\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "loss_track = checkpoint[\"loss_track\"]\n",
    "loss_validation_track = checkpoint[\"loss_validation_track\"]\n",
    "\n",
    "model.eval()\n",
    "print(\"Checkpoint loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T11:58:31.623518Z",
     "iopub.status.busy": "2025-02-27T11:58:31.623214Z",
     "iopub.status.idle": "2025-02-27T11:58:31.753726Z",
     "shell.execute_reply": "2025-02-27T11:58:31.752953Z",
     "shell.execute_reply.started": "2025-02-27T11:58:31.623493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (Arabic): أعد الكتاب إلى مكانه\n",
      "Predicted Translation (English): give the book back to the owner\n",
      "Ground Truth Translation (English): put the book back where it was\n",
      "\n",
      "Custom Input Translation:\n",
      "Source (Arabic): من أنت\n",
      "Predicted Translation (English): understood\n"
     ]
    }
   ],
   "source": [
    "def translate(model, sentence, src_tokenizer, src_vocab, tgt_vocab, max_len=200):\n",
    "    model.eval()\n",
    "    # Prepare source sentence by adding init and eos tokens\n",
    "    tokens = [\"ببدأ\"] + src_tokenizer(sentence) + [\"نهها\"]\n",
    "    src_indices = [src_vocab.stoi.get(tok, src_vocab.stoi[\"<unk>\"]) for tok in tokens]\n",
    "    src_tensor = torch.tensor(src_indices).unsqueeze(1).to(device)  # [src_len, 1]\n",
    "\n",
    "    trg_tokens = [\"<sos>\"]\n",
    "    for _ in range(max_len):\n",
    "        trg_indices = [tgt_vocab.stoi.get(tok, tgt_vocab.stoi[\"<unk>\"]) for tok in trg_tokens]\n",
    "        trg_tensor = torch.tensor(trg_indices).unsqueeze(1).to(device)  # [trg_len, 1]\n",
    "        output = model(src_tensor, trg_tensor)\n",
    "        next_token_idx = output.argmax(dim=2)[-1].item()\n",
    "        next_token = tgt_vocab.itos[next_token_idx]\n",
    "        if next_token == \"<eos>\":\n",
    "            break\n",
    "        trg_tokens.append(next_token)\n",
    "    # Return the prediction without the <sos> token\n",
    "    return \" \".join(trg_tokens[1:])\n",
    "\n",
    "# Helper function to convert tensor indices back to text (dropping special tokens)\n",
    "def indices_to_sentence(indices, vocab, remove_tokens):\n",
    "    tokens = [vocab.itos[idx] for idx in indices if idx not in remove_tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "import random\n",
    "# Pick a random sample from the validation dataset\n",
    "sample_idx = random.randint(0, len(valid_dataset) - 1)\n",
    "src_sample, tgt_sample = valid_dataset[sample_idx]\n",
    "\n",
    "# Convert the tensor indices into sentences\n",
    "src_sentence = indices_to_sentence(\n",
    "    src_sample.tolist(), \n",
    "    src_vocab, \n",
    "    remove_tokens=[src_vocab.stoi[\"ببدأ\"], src_vocab.stoi[\"نهها\"], src_vocab.stoi[\"<pad>\"]]\n",
    ")\n",
    "ground_truth = indices_to_sentence(\n",
    "    tgt_sample.tolist(),\n",
    "    tgt_vocab, \n",
    "    remove_tokens=[tgt_vocab.stoi[\"<sos>\"], tgt_vocab.stoi[\"<eos>\"], tgt_vocab.stoi[\"<pad>\"]]\n",
    ")\n",
    "\n",
    "predicted_translation = translate(model, src_sentence, myTokenizerAR, src_vocab, tgt_vocab)\n",
    "\n",
    "print(\"Source (Arabic):\", src_sentence)\n",
    "print(\"Predicted Translation (English):\", predicted_translation)\n",
    "print(\"Ground Truth Translation (English):\", ground_truth)\n",
    "\n",
    "def translate_sample_or_custom(model, src_vocab, tgt_vocab, src_tokenizer, valid_dataset, custom_sentence=None):\n",
    "    if custom_sentence:\n",
    "        # Translate the user-provided sentence\n",
    "        predicted_translation = translate(model, custom_sentence, src_tokenizer, src_vocab, tgt_vocab)\n",
    "        print(\"\\nCustom Input Translation:\")\n",
    "        print(\"Source (Arabic):\", custom_sentence)\n",
    "        print(\"Predicted Translation (English):\", predicted_translation)\n",
    "    else:\n",
    "        # Pick a random sample from the validation dataset\n",
    "        sample_idx = random.randint(0, len(valid_dataset) - 1)\n",
    "        src_sample, tgt_sample = valid_dataset[sample_idx]\n",
    "\n",
    "        # Convert tensor indices to sentence\n",
    "        src_sentence = indices_to_sentence(\n",
    "            src_sample.tolist(), \n",
    "            src_vocab, \n",
    "            remove_tokens=[src_vocab.stoi[\"ببدأ\"], src_vocab.stoi[\"نهها\"], src_vocab.stoi[\"<pad>\"]]\n",
    "        )\n",
    "        ground_truth = indices_to_sentence(\n",
    "            tgt_sample.tolist(),\n",
    "            tgt_vocab, \n",
    "            remove_tokens=[tgt_vocab.stoi[\"<sos>\"], tgt_vocab.stoi[\"<eos>\"], tgt_vocab.stoi[\"<pad>\"]]\n",
    "        )\n",
    "\n",
    "        predicted_translation = translate(model, src_sentence, src_tokenizer, src_vocab, tgt_vocab)\n",
    "\n",
    "        print(\"\\nRandom Sample Translation:\")\n",
    "        print(\"Source (Arabic):\", src_sentence)\n",
    "        print(\"Predicted Translation (English):\", predicted_translation)\n",
    "        print(\"Ground Truth Translation (English):\", ground_truth)\n",
    "\n",
    "# Usage\n",
    "custom_input = \"من أنت\"\n",
    "\n",
    "translate_sample_or_custom(model, src_vocab, tgt_vocab, myTokenizerAR, valid_dataset, custom_sentence=custom_input)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
